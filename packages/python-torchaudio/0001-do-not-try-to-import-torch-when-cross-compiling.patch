--- a/setup.py.orig
+++ b/setup.py
@@ -7,7 +7,6 @@
 import sys
 from pathlib import Path
 
-import torch
 from setuptools import find_packages, setup
 from tools import setup_helpers
 
@@ -116,11 +115,34 @@
             yield path, url
 
 
+def _download_url_to_file(url, dst, progress):
+    # From torch.hub.download_url_to_file
+    from urllib.request import urlopen, Request
+    import tempfile
+
+    req = Request(url, headers={"User-Agent": "torch.hub"})
+    u = urlopen(req)
+
+    # We deliberately save it in a temp file and move it after
+    # download is complete. This prevents a local working checkpoint
+    # being overridden by a broken download.
+    dst = os.path.expanduser(dst)
+    dst_dir = os.path.dirname(dst)
+    f = tempfile.NamedTemporaryFile(delete=False, dir=dst_dir)
+    while True:
+        buffer = u.read(8192)
+        if len(buffer) == 0:
+            break
+        f.write(buffer)
+    f.close()
+    shutil.move(f.name, dst)
+
+
 def _fetch_archives(src):
     for dest, url in src:
         if not dest.exists():
             print(f" --- Fetching {os.path.basename(dest)}")
-            torch.hub.download_url_to_file(url, dest, progress=False)
+            _download_url_to_file(url, dest, progress=False)
 
 
 def _fetch_third_party_libraries():
diff -u -r ../cache/tmp-checkout/tools/setup_helpers/extension.py ./tools/setup_helpers/extension.py
--- ../cache/tmp-checkout/tools/setup_helpers/extension.py	2024-10-03 18:27:06.446948017 +0000
+++ ./tools/setup_helpers/extension.py	2024-10-04 12:28:00.563912841 +0000
@@ -4,10 +4,9 @@
 import subprocess
 from pathlib import Path
 
-import torch
 from setuptools import Extension
 from setuptools.command.build_ext import build_ext
-from torch.utils.cpp_extension import CUDA_HOME
+CUDA_HOME = None
 
 __all__ = [
     "get_ext_modules",
@@ -38,11 +37,13 @@
 _BUILD_RIR = _get_build("BUILD_RIR", True)
 _BUILD_RNNT = _get_build("BUILD_RNNT", True)
 _USE_FFMPEG = _get_build("USE_FFMPEG", True)
-_USE_ROCM = _get_build("USE_ROCM", torch.backends.cuda.is_built() and torch.version.hip is not None)
-_USE_CUDA = _get_build("USE_CUDA", torch.backends.cuda.is_built() and torch.version.hip is None)
+_USE_ROCM = _get_build("USE_ROCM", False)
+_USE_CUDA = _get_build("USE_CUDA", False)
 _BUILD_ALIGN = _get_build("BUILD_ALIGN", True)
 _BUILD_CUDA_CTC_DECODER = _get_build("BUILD_CUDA_CTC_DECODER", _USE_CUDA)
-_USE_OPENMP = _get_build("USE_OPENMP", True) and "ATen parallel backend: OpenMP" in torch.__config__.parallel_info()
+_USE_OPENMP = _get_build("USE_OPENMP", False)
+_CMAKE_PREFIX_PATH = os.environ.get("TORCHAUDIO_CMAKE_PREFIX_PATH", "@TERMUX_PREFIX@")
+_CMAKE_MAKE_PROGRAM = subprocess.check_output(['which', 'ninja'], text=True).strip()
 _TORCH_CUDA_ARCH_LIST = os.environ.get("TORCH_CUDA_ARCH_LIST", None)
 
 
@@ -124,8 +125,9 @@
 
         cmake_args = [
             f"-DCMAKE_BUILD_TYPE={cfg}",
-            f"-DCMAKE_PREFIX_PATH={torch.utils.cmake_prefix_path}",
+            f"-DCMAKE_PREFIX_PATH={_CMAKE_PREFIX_PATH}",
             f"-DCMAKE_INSTALL_PREFIX={extdir}",
+            f"-DCMAKE_MAKE_PROGRAM={_CMAKE_MAKE_PROGRAM}",
             "-DCMAKE_VERBOSE_MAKEFILE=ON",
             f"-DPython_INCLUDE_DIR={distutils.sysconfig.get_python_inc()}",
             f"-DBUILD_CPP_TEST={'ON' if _BUILD_CPP_TEST else 'OFF'}",
